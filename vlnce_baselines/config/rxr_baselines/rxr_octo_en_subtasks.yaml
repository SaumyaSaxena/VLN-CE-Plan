BASE_TASK_CONFIG_PATH: habitat_extensions/config/rxr_vlnce_english_subtasks.yaml
TRAINER_NAME: octo_trainer
SIMULATOR_GPU_IDS: [1] # Evals run on these GPUs
TORCH_GPU_ID: 0
NUM_ENVIRONMENTS: 10 # Number of envs per GPU
TENSORBOARD_DIR: outputs/rxr_octo_en_subtasks
CHECKPOINT_FOLDER: outputs/rxr_octo_en_subtasks
CONTEXT_LEARNING: False
OCTO_CONFIG_PATH: '/home/saumyas/Projects/VLN-CE-Plan/vlnce_baselines/config/rxr_baselines/rxr_octo_config.yaml'
DATASET: OctoTimeStepsTeacherRecollectionDataset # OctoTimeStepsTeacherRecollectionDataset, OctoTeacherRecollectionDataset

wandb:
  entity: iam-lab
  group: octo_subtasks
  project: vlnce_plan
  name: subtasks_discrete_wind1_horizon1_frozen_vision_half_data
  saver:
    upload: True
    save_top_k: 5
wandb_resume_id: null

EVAL:
  USE_CKPT_CONFIG: True
  SPLIT: val_seen
  LANGUAGES: [en-US, en-IN]
  EPISODE_COUNT: -1
  SAMPLE: True
  SAVE_VIDEO: False
  VIDEO_SAVE_FREQ: 500
  VIDEO_SAVE_LOC: ['disk'] # options: "disk", "tensorboard"
  SAVE_RESULTS: False
  logger_type: 'wandb' # 'wandb', 'tb'
  wandb_load:
    run_path: 'iam-lab/vlnce_plan/041jcv8g'
    file: checkpoints/ckpt_epoch_2_step_56868_action_loss_5.276.pth
    entity: iam-lab
    project: vlnce_plan_eval
    group: octo
    name: subtasks_discreteAH_wind_horizon4_SD1 #subtasks_discreteAH_step_sched_wind3_horizon4_SD2
  tb_load:
    EVAL_CKPT_PATH_DIR: outputs/rxr_octo_en_subtasks/2024_01_16-15_35_57/checkpoints/ckpt.14.pth # If this is a directory, evaluate all checkpoints. Else evaluate the specified checkpoint.pth
    EVAL_LOG_DIR: outputs/rxr_octo_en_subtasks/2024_01_16-15_35_57

  EVAL_TASK_CONFIG:
    TASK:
      SUCCESS_DISTANCE: 1.0
      SUCCESS:
        SUCCESS_DISTANCE: 1.0
      SUCCESS_NO_STOP:
        SUCCESS_DISTANCE: 1.0
      ORACLE_SUCCESS:
        SUCCESS_DISTANCE: 1.0
      NDTW:
        SUCCESS_DISTANCE: 1.0
    ENVIRONMENT:
      MAX_EPISODE_STEPS: 300
  COMMON:
    SIMULATOR_GPU_IDS: [2] # Evals run on these GPUs
    NUM_ENVIRONMENTS: 10 # Number of envs per GPU
    TORCH_GPU_ID: 0

MODEL:
  policy_name: OctoPolicy
  INSTRUCTION_ENCODER:
    bidirectional: True
    sensor_uuid: rxr_instruction
    embedding_size: 768

RL:
  POLICY:
    OBS_TRANSFORMS:
      ENABLED_TRANSFORMS: [ResizeShortestEdge, CenterCropperPerSensor]
      CENTER_CROPPER_PER_SENSOR:
        SENSOR_CROPS:
          rgb: (256, 256)
          depth: (256, 256)

IL:
  batch_size: 300
  epochs: 20
  inflection_weight_coef: 1.9
  load_from_ckpt: False
  ckpt_to_load: outputs/rxr_octo_en_subtasks/2024_01_12-14_46_50/checkpoints/ckpt.14.pth

  OCTO_TRAINER:
    effective_batch_size: -1
    scale_bits: 1.0 # used when action_repr=bits
    preload_size: 9600
    preload_trajectories_file: False
    trajectories_file: data/trajectories_dirs/rxr_en_guide_trim250/trajectories_subtasks_merged.json.gz
    max_traj_len: 250  # 1.3% of episodes in the English training split are above 250
    logger_type: 'wandb' # 'wandb', 'tb'

train:
  optimizer:
    name: AdamW
    Adam:
      lr: 2.5e-4
      eps: 1.0e-8
    AdamW:
      lr: 1.0e-5
      eps: 1.0e-8
      weight_decay: 0.01

  # Scheduler config
  scheduler:
    use: True
    name: timm_cosine
    update_per: epoch # epoch
    cooldown_ratio: 0.1
    warmup_ratio: 0.2
    CosineAnnealingLR:
      eta_min: 0.00001
      t_max: -1
      last_epoch: -1    # No warm restarts (simply follows cosine decay)
    timm_cosine:
      use_timm: True
      sched: cosine
      # epochs are updated in code: epochs <- total_epochs - warmup - cooldown
      epochs: 15  # Total epochs to run (warmup + decay + cooldown)
      min_lr: 1.0e-6         # k
      warmup_lr: 1.0e-5
      warmup_epochs: 1
      cooldown_epochs: 7

  grad_clip:
    use: True
    norm: 1.0