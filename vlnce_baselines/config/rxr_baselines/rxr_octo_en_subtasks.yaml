BASE_TASK_CONFIG_PATH: habitat_extensions/config/rxr_vlnce_english_subtasks.yaml
TRAINER_NAME: octo_trainer
SIMULATOR_GPU_IDS: [1] # Evals run on these GPUs
TORCH_GPU_ID: 2
NUM_ENVIRONMENTS: 5 # Number of envs per GPU
TENSORBOARD_DIR: outputs/rxr_octo_en_subtasks
CHECKPOINT_FOLDER: outputs/rxr_octo_en_subtasks
CONTEXT_LEARNING: True
OCTO_CONFIG_PATH: '/home/saumyas/Projects/VLN-CE-Plan/vlnce_baselines/config/rxr_baselines/rxr_octo_config.yaml'

wandb:
  entity: iam-lab
  group: octo
  project: vlnce_plan
  name: discrete_loss
  saver:
    upload: True
    save_top_k: 5
wandb_resume_id: null

EVAL:
  USE_CKPT_CONFIG: True
  SPLIT: val_seen
  LANGUAGES: [en-US, en-IN]
  EPISODE_COUNT: -1
  SAMPLE: True
  EVAL_CKPT_PATH_DIR: outputs/rxr_octo_en_subtasks/2024_01_16-15_35_57/checkpoints/ckpt.14.pth # If this is a directory, evaluate all checkpoints. Else evaluate the specified checkpoint.pth
  EVAL_LOG_DIR: outputs/rxr_octo_en_subtasks/2024_01_16-15_35_57
  SAVE_VIDEO: True
  VIDEO_SAVE_FREQ: 500
  VIDEO_SAVE_LOC: ['disk'] # options: "disk", "tensorboard"
  SAVE_RESULTS: False
  VL_MODEL: 'gemini-pro-vision' # 'blip2', 'gemini-pro-vision'
  LL_MODEL: 'gpt-3.5-turbo' # 'gemini-pro'
  MAX_STEPS_PER_SUBTASK: 50
  VIDEO_SUBSAMPLE: 10
  USE_SUMMARY: True

  EVAL_TASK_CONFIG:
    TASK:
      SUCCESS_DISTANCE: 2.0
      SUCCESS:
        SUCCESS_DISTANCE: 2.0
      ORACLE_SUCCESS:
        SUCCESS_DISTANCE: 2.0
      NDTW:
        SUCCESS_DISTANCE: 2.0
        GT_PATH: data/datasets/RxR_VLNCE_v0/{split}/{split}_{role}_gt.json.gz
      RXR_INSTRUCTION_SENSOR:
        use_bert_features: True
    ENVIRONMENT:
      MAX_EPISODE_STEPS: 300
    DATASET:
      DATA_PATH: data/datasets/RxR_VLNCE_v0/{split}/{split}_{role}_high_level_instr.json.gz
  COMMON:
    SIMULATOR_GPU_IDS: [1] # Evals run on these GPUs
    NUM_ENVIRONMENTS: 1 # Number of envs per GPU
    TORCH_GPU_ID: 0

MODEL:
  policy_name: OctoPolicy
  INSTRUCTION_ENCODER:
    bidirectional: True
    sensor_uuid: rxr_instruction
    embedding_size: 768

RL:
  POLICY:
    OBS_TRANSFORMS:
      ENABLED_TRANSFORMS: [ResizeShortestEdge, CenterCropperPerSensor]
      CENTER_CROPPER_PER_SENSOR:
        SENSOR_CROPS:
          rgb: (256, 256)
          depth: (256, 256)

IL:
  batch_size: 4
  epochs: 15
  inflection_weight_coef: 1.9
  load_from_ckpt: False
  ckpt_to_load: outputs/rxr_octo_en_subtasks/2024_01_12-14_46_50/checkpoints/ckpt.14.pth

  OCTO_TRAINER:
    preload_size: 30
    preload_trajectories_file: False
    trajectories_file: data/trajectories_dirs/rxr_en_guide_trim250/trajectories_subtasks_merged.json.gz
    max_traj_len: 250  # 1.3% of episodes in the English training split are above 250
    logger_type: 'wandb' # 'wandb', 'tb'

train:
  optimizer:
    name: AdamW
    Adam:
      lr: 2.5e-4
      eps: 1.0e-8
    AdamW:
      lr: 2.5e-4
      eps: 1.0e-8
      weight_decay: 0.01

  # Scheduler config
  scheduler:
    use: False
    name: timm_cosine
    CosineAnnealingLR:
      eta_min: 0.00001
      t_max: -1
      last_epoch: -1    # No warm restarts (simply follows cosine decay)
    timm_cosine:
      use_timm: True
      sched: cosine
      # epochs are updated in code: epochs <- total_epochs - warmup - cooldown
      epochs: ${IL.epochs}  # Total epochs to run (warmup + decay + cooldown)
      min_lr: 1.0e-5         # k
      warmup_lr: 1.0e-6
      warmup_epochs: 10
      cooldown_epochs: 5

  grad_clip:
    use: True
    norm: 1.0